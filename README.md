# SRE Homelab: Production Multi-Cluster Kubernetes Infrastructure

> A professional homelab demonstrating enterprise-level Site Reliability Engineering practices across bare metal and virtualized Kubernetes clusters with GitOps workflows.

[![Infrastructure](https://img.shields.io/badge/Infrastructure-Proxmox%20%2B%20Talos-blue)](#architecture)
[![Kubernetes](https://img.shields.io/badge/Kubernetes-Multi--Cluster-green)](#clusters)
[![GitOps](https://img.shields.io/badge/GitOps-ArgoCD-purple)](#gitops)
[![Load Balancer](https://img.shields.io/badge/LoadBalancer-MetalLB-orange)](#networking)

## ğŸ—ï¸ Architecture Overview

This homelab demonstrates a production-grade infrastructure setup featuring:

- **ğŸ–¥ï¸ Server 1**: Proxmox hypervisor hosting 3-node k3s cluster
- **ğŸ”§ Server 2**: Bare metal Talos Linux single-node cluster  
- **ğŸ’» Control Plane**: Arch Linux ThinkPad for infrastructure management
- **ğŸŒ Network**: Segmented VLANs with load balancing and GitOps integration

### Technology Stack

| Component | Technology | Purpose | Status |
|-----------|------------|---------|--------|
| **Hypervisor** | Proxmox VE | VM management | âœ… Production |
| **Bare Metal OS** | Talos Linux | Immutable Kubernetes OS | âœ… Production |
| **Kubernetes** | k3s + Talos | Container orchestration | âœ… Multi-cluster |
| **Load Balancer** | MetalLB | Service exposure | âœ… Both clusters |
| **GitOps** | ArgoCD | Declarative deployment | âœ… Operational |
| **Network** | VLAN segmentation | Traffic isolation | âœ… Configured |
| **Management** | Arch Linux | Development/automation | âœ… Ready |

## ğŸ”§ Infrastructure Details

### Cluster Specifications

#### k3s Cluster (Server 1 - Virtualized)
- **Nodes**: 3 VMs (1 master + 2 workers)
- **Resources**: 4 CPU cores, 8GB RAM per node
- **Storage**: Proxmox local storage
- **Purpose**: Stable production workloads
- **Load Balancer**: MetalLB (shared pool)

#### Talos Cluster (Server 2 - Bare Metal)
- **Nodes**: 1 bare metal server
- **OS**: Talos Linux (immutable, API-managed)
- **Purpose**: GitOps, experimental workloads
- **Management**: 100% API-driven (no SSH)
- **Load Balancer**: MetalLB (shared pool)

## ğŸš€ Current Deployment Status

### Core Services

| Service | Location | External IP | Status | Purpose |
|---------|----------|-------------|--------|---------|
| **k3s API Server** | Server 1 VM | 10.10.20.20:6443 | âœ… Running | k3s cluster management |
| **Talos API Server** | Server 2 BM | 10.10.20.10:6443 | âœ… Running | Talos cluster management |
| **ArgoCD UI** | Talos cluster | 10.10.20.200 | âœ… Running | GitOps management |
| **MetalLB (k3s)** | k3s cluster | Pool: .200-.250 | âœ… Running | Load balancing |
| **MetalLB (Talos)** | Talos cluster | Pool: .200-.250 | âœ… Running | Load balancing |

### GitOps Workflow Status
- âœ… **ArgoCD installed** and accessible via LoadBalancer
- âœ… **Repository structure** created for GitOps manifests
- âœ… **Multi-cluster ready** for cross-cluster deployments
- ğŸš§ **First application** deployment in progress

## ğŸ’» Daily Operations

### Cluster Management from Arch Linux

```bash
# Switch between clusters
kubectl config use-context k3s-cluster        # 3-node virtualized
kubectl config use-context talos-cluster      # 1-node bare metal

# Check cluster health
kubectl get nodes
kubectl get pods --all-namespaces

# Talos-specific operations
talosctl --nodes 10.10.20.10 health
talosctl --nodes 10.10.20.10 service
```

### GitOps Workflow

```bash
# Make infrastructure changes
vim gitops/manifests/application.yaml

# Commit and push
git add gitops/
git commit -m "Deploy new application"
git push origin main

# ArgoCD automatically syncs changes
# Monitor via ArgoCD UI: https://10.10.20.200
```

### Load Balancer Management

```bash
# Check MetalLB IP assignments
kubectl get svc --all-namespaces | grep LoadBalancer

# IP pool utilization
kubectl get ipaddresspool -n metallb-system -o yaml
```

## ğŸ“Š Monitoring & Observability

### Current Capabilities
- **Multi-cluster visibility** via kubectl contexts
- **ArgoCD application health** monitoring
- **MetalLB service exposure** tracking
- **Node resource monitoring** via kubectl top

### Planned Enhancements
- [ ] **Prometheus + Grafana** cross-cluster monitoring
- [ ] **Jaeger** distributed tracing
- [ ] **AlertManager** critical alerts
- [ ] **Custom dashboards** for both clusters

## ğŸ”’ Security Implementation

### Network Security
- **VLAN segmentation** isolates cluster traffic
- **MetalLB L2 mode** for secure load balancing
- **Dedicated IP ranges** prevent conflicts

### Cluster Security
- **Talos immutable OS** prevents runtime modifications
- **API-only management** eliminates SSH attack surface
- **GitOps workflows** provide audit trails
- **Multi-cluster isolation** limits blast radius

### Access Control
- **kubectl contexts** for cluster isolation
- **ArgoCD RBAC** for deployment permissions
- **Talos API certificates** for secure communication

## ğŸ› ï¸ Development Workflow

### Infrastructure as Code
```bash
# Repository structure
homelab/
â”œâ”€â”€ docs/                    # Documentation
â”œâ”€â”€ gitops/
â”‚   â”œâ”€â”€ applications/        # ArgoCD application definitions
â”‚   â””â”€â”€ manifests/          # Kubernetes manifests
â”œâ”€â”€ talos/
â”‚   â”œâ”€â”€ configs/            # Talos configuration files
â”‚   â””â”€â”€ manifests/          # Talos-specific resources
â”œâ”€â”€ terraform/              # Infrastructure automation (planned)
â”œâ”€â”€ ansible/                # Configuration management (planned)
â””â”€â”€ monitoring/             # Observability configs (planned)
```

### Deployment Process
1. **Develop locally** on Arch Linux workstation
2. **Test on k3s cluster** (staging environment)
3. **Commit to Git** with proper documentation
4. **ArgoCD syncs automatically** to Talos cluster
5. **Monitor via LoadBalancer** endpoints

## ğŸ¯ SRE Skills Demonstrated

### Core Competencies
- âœ… **Multi-cluster Kubernetes management**
- âœ… **Bare metal infrastructure deployment**
- âœ… **GitOps implementation with ArgoCD**
- âœ… **Load balancer configuration and management**
- âœ… **Network segmentation and VLAN configuration**
- âœ… **Infrastructure as Code practices**

### Advanced Technologies
- âœ… **Talos Linux** - API-managed immutable OS
- âœ… **MetalLB** - Kubernetes native load balancing
- âœ… **Cross-cluster networking** and service discovery
- âœ… **Declarative infrastructure management**

### Operational Excellence
- âœ… **Documentation-driven development**
- âœ… **Version-controlled infrastructure**
- âœ… **Automated deployment pipelines**
- âœ… **Multi-environment management**

## ğŸ”„ Phase Completion Status

### âœ… Phase 4: Talos Conversion (Complete)
- [x] Server 2 converted to bare metal Talos
- [x] Single-node Kubernetes cluster operational
- [x] MetalLB installed and configured
- [x] LoadBalancer services functional
- [x] Cross-cluster networking validated

### âœ… Phase 5: Cross-Cluster Integration (Complete)
- [x] MetalLB installed on both clusters
- [x] ArgoCD deployed on Talos cluster
- [x] GitOps repository structure created
- [x] LoadBalancer access to ArgoCD UI
- [x] Multi-cluster kubectl configuration

### ğŸš§ Phase 6: Advanced Projects (In Progress)
- [x] GitOps workflow established
- [ ] Cross-cluster monitoring with Prometheus
- [ ] Service mesh implementation (Istio/Linkerd)
- [ ] Automated backup validation
- [ ] Chaos engineering testing

## ğŸŒŸ Success Metrics

### Technical Achievements
- **2 Kubernetes clusters** running different architectures
- **100% GitOps coverage** for application deployments
- **Zero downtime** LoadBalancer configuration
- **API-driven infrastructure** management
- **Multi-context management** from single workstation

### Career Development Value
This homelab provides hands-on experience with technologies used at:
- **Major tech companies** (Kubernetes, GitOps, immutable infrastructure)
- **Cloud-native startups** (ArgoCD, MetalLB, declarative management)
- **Enterprise environments** (multi-cluster, network segmentation, security)

## ğŸš€ Next Steps

### Short-term Goals
1. **Deploy monitoring stack** (Prometheus + Grafana)
2. **Implement cross-cluster service discovery**
3. **Add backup automation and validation**
4. **Create custom Grafana dashboards**

### Long-term Vision
1. **Add third cluster** for true multi-region simulation
2. **Implement service mesh** for advanced traffic management
3. **Add ML/AI workloads** using GPU nodes
4. **Develop custom operators** for specialized workloads

## ğŸ“ Connect

- **GitHub**: [https://www.github.com/eelbros]
- **LinkedIn**: [https://www.linkedin.com/in/zameelh]

---

*This homelab represents enterprise-grade SRE practices implemented in a home environment, demonstrating proficiency with cutting-edge infrastructure technologies and operational methodologies used in production environments at scale.*
